# services/arangodb_service.py
# ë³€ê²½ í•µì‹¬:
# - ë¡œì»¬ ë””ìŠ¤í¬ ëŒ€ì‹  ArangoDBì— "íŒŒì¼ ë³¸ë¬¸(content)"ë¥¼ ì €ì¥í•˜ëŠ” repo_files ì»¬ë ‰ì…˜ ì¶”ê°€
# - repos ë©”íƒ€ ì»¬ë ‰ì…˜ ì¶”ê°€
# - code_analysisëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€(íŒŒì‹± ê²°ê³¼ ì €ì¥)
# - ê³µí†µ insert/get ìœ í‹¸ ìœ ì§€
# - ì¸ë±ìŠ¤ ì¶”ê°€ë¡œ ì¡°íšŒ ì„±ëŠ¥ ë³´ê°•

from datetime import datetime
from typing import List, Optional

from arango import ArangoClient
from arango.exceptions import AQLQueryExecuteError, ArangoServerError

from config import (
    ARANGODB_HOST, ARANGODB_PORT,
    ARANGODB_USERNAME, ARANGODB_PASSWORD, ARANGODB_DB
)

# í˜¸ìŠ¤íŠ¸/í¬íŠ¸ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ë°›ì•„ ì›ê²©/ë¡œì»¬ ëª¨ë‘ ëŒ€ì‘
client = ArangoClient(hosts=f"http://{ARANGODB_HOST}:{ARANGODB_PORT}")
db = client.db(ARANGODB_DB, username=ARANGODB_USERNAME, password=ARANGODB_PASSWORD)


def ensure_collections():
    """í•„ìš” ì»¬ë ‰ì…˜/ì¸ë±ìŠ¤ ë³´ì¥ (ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œí•´ë„ ì•ˆì „)"""
    for name in ["repos", "repo_files", "code_analysis", "mindmap_nodes", "mindmap_edges", "code_recommendations"]:
        if not db.has_collection(name):
            if name.endswith("_edges"):
                db.create_collection(name, edge=True)
            else:
                db.create_collection(name)

    # ì¸ë±ìŠ¤ ìƒì„±(ì¤‘ë³µ ì—ëŸ¬ëŠ” ë¬´ì‹œ)
    try:
        rf = db.collection("repo_files")
        rf.add_hash_index(["repo_id"])
        rf.add_hash_index(["repo_id", "path"])
    except Exception:
        pass

    try:
        ca = db.collection("code_analysis")
        ca.add_hash_index(["repo_id"])
        ca.add_hash_index(["filename"])
    except Exception:
        pass


def insert_document(collection_name: str, data: dict):
    """ê³µí†µ insert. overwrite=Trueë¡œ ë©±ë“± ì²˜ë¦¬"""
    ensure_collections()
    if not db.has_collection(collection_name):
        if collection_name.endswith("_edges") or collection_name == "mindmap_edges":
            db.create_collection(collection_name, edge=True)
        else:
            db.create_collection(collection_name)
    collection = db.collection(collection_name)
    return collection.insert(data, overwrite=True)


def document_exists(collection_name: str, key: str) -> bool:
    if not db.has_collection(collection_name):
        return False
    return db.collection(collection_name).has(key)


def get_document_by_key(collection_name: str, key: str):
    if not db.has_collection(collection_name):
        return None
    return db.collection(collection_name).get({"_key": key})


def get_documents_by_repo_url_prefix(collection_name: str, prefix: str):
    aql = f"""
    FOR doc IN {collection_name}
      /* STARTS_WITH(doc.repo_url, @prefix) ëŒ€ì‹  LIKEë¡œ ëŒ€ì²´ */
      FILTER doc.repo_url LIKE CONCAT(@prefix, '%')
      RETURN doc
    """
    return list(db.aql.execute(aql, bind_vars={"prefix": prefix}))



def get_documents_by_key_prefix(collection_name: str, prefix: str):
    aql = f"""
    FOR doc IN {collection_name}
      /* STARTS_WITH(doc._key, @prefix) ëŒ€ì‹  LIKEë¡œ ëŒ€ì²´ */
      FILTER doc._key LIKE CONCAT(@prefix, '%')
      RETURN doc
    """
    return list(db.aql.execute(aql, bind_vars={"prefix": prefix}))



# ---------- ë ˆí¬/íŒŒì¼ ì €ì¥ ì „ìš© ìœ í‹¸ ----------

def path_key(repo_id: str, path: str) -> str:
    """_key ê·œì¹™: repo_id__ê²½ë¡œ(ìŠ¬ë˜ì‹œëŠ” __ë¡œ)"""
    return f"{repo_id}__{path.replace('/', '__')}"


def upsert_repo(repo_id: str, repo_url: str, default_branch: str = "main"):
    """ë ˆí¬ ë©”íƒ€ upsert"""
    ensure_collections()
    coll = db.collection("repos")
    doc = {
        "_key": repo_id,
        "repo_url": repo_url,
        "default_branch": default_branch,
        "fetched_at": datetime.utcnow().isoformat() + "Z",
    }
    if coll.has(repo_id):
        return coll.update(doc)
    return coll.insert(doc)


def upsert_repo_file(repo_id: str, path: str, language: str, content: str, size: int, sha: Optional[str] = None):
    """íŒŒì¼ ë³¸ë¬¸ ì €ì¥ì†Œ. contentê¹Œì§€ DBì— ì €ì¥."""
    ensure_collections()
    coll = db.collection("repo_files")
    key = path_key(repo_id, path)
    doc = {
        "_key": key,
        "repo_id": repo_id,
        "path": path,              # repo ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ
        "language": language,
        "size": size,
        "sha": sha,
        "content": content,        # ğŸ”¸ íŒŒì¼ ë³¸ë¬¸
        "fetched_at": datetime.utcnow().isoformat() + "Z",
    }
    if coll.has(key):
        return coll.update(doc)
    return coll.insert(doc)


def get_repo_file_content(repo_id: str, path: str) -> Optional[str]:
    """repo_filesì—ì„œ ë³¸ë¬¸ ë°”ë¡œ ì¡°íšŒ"""
    ensure_collections()
    key = path_key(repo_id, path)
    if not db.collection("repo_files").has(key):
        return None
    return db.collection("repo_files").get(key).get("content")


def list_repo_files(repo_id: str) -> List[dict]:
    """ë ˆí¬ì˜ íŒŒì¼ ëª©ë¡/ë©”íƒ€ ì¡°íšŒ"""
    ensure_collections()
    aql = """
    FOR f IN repo_files
      FILTER f.repo_id == @repo_id
      RETURN { path: f.path, language: f.language, size: f.size, fetched_at: f.fetched_at }
    """
    return list(db.aql.execute(aql, bind_vars={"repo_id": repo_id}))


def ensure_mindmap_graph_exists():
    if not db.has_graph("mindmap_graph"):
        graph = db.create_graph("mindmap_graph")
        db.create_collection("mindmap_nodes")
        db.create_collection("mindmap_edges", edge=True)
        graph.create_edge_definition(
            edge_collection="mindmap_edges",
            from_vertex_collections=["mindmap_nodes"],
            to_vertex_collections=["mindmap_nodes"]
        )
    else:
        if not db.has_collection("mindmap_nodes"):
            db.create_collection("mindmap_nodes")
        if not db.has_collection("mindmap_edges"):
            db.create_collection("mindmap_edges", edge=True)
